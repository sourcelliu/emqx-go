# EMQX-Go æ··æ²Œå·¥ç¨‹æµ‹è¯•è®¡åˆ’

## ç›®å½•

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [æµ‹è¯•ç›®æ ‡](#æµ‹è¯•ç›®æ ‡)
3. [æµ‹è¯•ç¯å¢ƒ](#æµ‹è¯•ç¯å¢ƒ)
4. [Chaos Mesh å®‰è£…](#chaos-mesh-å®‰è£…)
5. [æµ‹è¯•åœºæ™¯](#æµ‹è¯•åœºæ™¯)
6. [æµ‹è¯•ç”¨ä¾‹](#æµ‹è¯•ç”¨ä¾‹)
7. [ç›‘æ§ä¸éªŒè¯](#ç›‘æ§ä¸éªŒè¯)
8. [æ‰§è¡Œè®¡åˆ’](#æ‰§è¡Œè®¡åˆ’)
9. [æ•…éšœæ¢å¤éªŒè¯](#æ•…éšœæ¢å¤éªŒè¯)
10. [é™„å½•](#é™„å½•)

---

## æ¦‚è¿°

### ä»€ä¹ˆæ˜¯æ··æ²Œå·¥ç¨‹ï¼Ÿ

æ··æ²Œå·¥ç¨‹æ˜¯ä¸€ç§é€šè¿‡åœ¨ç³»ç»Ÿä¸­ä¸»åŠ¨æ³¨å…¥æ•…éšœæ¥æµ‹è¯•ç³»ç»Ÿå¼¹æ€§å’Œå¯é æ€§çš„æ–¹æ³•ã€‚é€šè¿‡æ¨¡æ‹ŸçœŸå®ä¸–ç•Œä¸­å¯èƒ½å‘ç”Ÿçš„å„ç§æ•…éšœåœºæ™¯ï¼Œæˆ‘ä»¬å¯ä»¥:

- ğŸ” å‘ç°ç³»ç»Ÿçš„è–„å¼±ç¯èŠ‚
- ğŸ’ª éªŒè¯å®¹é”™æœºåˆ¶çš„æœ‰æ•ˆæ€§
- ğŸ“Š å»ºç«‹ç³»ç»Ÿå¯é æ€§åŸºå‡†
- ğŸ›¡ï¸ æé«˜ç³»ç»Ÿçš„æ•´ä½“éŸ§æ€§

### EMQX-Go ç³»ç»Ÿç‰¹ç‚¹

EMQX-Go æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼ MQTT æ¶ˆæ¯ä»£ç†,å…·æœ‰ä»¥ä¸‹å…³é”®ç‰¹æ€§:

- **Actor æ¨¡å‹**: ä½¿ç”¨ OTP é£æ ¼çš„ Actor å¹¶å‘æ¨¡å‹
- **åˆ†å¸ƒå¼é›†ç¾¤**: æ”¯æŒå¤šèŠ‚ç‚¹é›†ç¾¤å’Œè‡ªåŠ¨æœåŠ¡å‘ç°
- **gRPC é€šä¿¡**: èŠ‚ç‚¹é—´ä½¿ç”¨ gRPC è¿›è¡Œæ¶ˆæ¯è·¯ç”±å’ŒçŠ¶æ€åŒæ­¥
- **Kubernetes åŸç”Ÿ**: æ”¯æŒ K8s ç¯å¢ƒä¸‹çš„è‡ªåŠ¨å‘ç°
- **ä¼šè¯ç®¡ç†**: æ”¯æŒæŒä¹…åŒ–ä¼šè¯å’Œ QoS ä¿è¯

### æµ‹è¯•èŒƒå›´

æœ¬æµ‹è¯•è®¡åˆ’è¦†ç›–ä»¥ä¸‹æ–¹é¢:

| ç±»åˆ« | æµ‹è¯•å†…å®¹ |
|------|---------|
| ğŸŒ **ç½‘ç»œ** | ç½‘ç»œå»¶è¿Ÿã€ä¸¢åŒ…ã€åˆ†åŒºã€å¸¦å®½é™åˆ¶ |
| ğŸ’» **Pod** | Pod æ•…éšœã€é‡å¯ã€åˆ é™¤ |
| ğŸ–¥ï¸ **èŠ‚ç‚¹** | èŠ‚ç‚¹æ•…éšœã€èµ„æºè€—å°½ |
| â° **æ—¶é—´** | æ—¶é’Ÿåç§»ã€æ—¶é—´è·³å˜ |
| ğŸ”§ **å‹åŠ›** | CPUã€å†…å­˜ã€IO å‹åŠ› |
| âš™ï¸ **å†…æ ¸** | ç³»ç»Ÿè°ƒç”¨æ•…éšœ |

---

## æµ‹è¯•ç›®æ ‡

### ä¸»è¦ç›®æ ‡

1. **å¯ç”¨æ€§éªŒè¯**
   - éªŒè¯é›†ç¾¤åœ¨éƒ¨åˆ†èŠ‚ç‚¹æ•…éšœæ—¶èƒ½å¦ç»§ç»­æä¾›æœåŠ¡
   - éªŒè¯æ¶ˆæ¯è·¯ç”±çš„å¯é æ€§
   - éªŒè¯ä¼šè¯æ¢å¤æœºåˆ¶

2. **æ€§èƒ½å½±å“è¯„ä¼°**
   - è¯„ä¼°æ•…éšœå¯¹æ¶ˆæ¯å»¶è¿Ÿçš„å½±å“
   - è¯„ä¼°æ•…éšœå¯¹ååé‡çš„å½±å“
   - è¯„ä¼°æ¢å¤æ—¶é—´ç›®æ ‡ (RTO)

3. **æ•…éšœæ¢å¤èƒ½åŠ›**
   - éªŒè¯ Actor Supervisor çš„å´©æºƒæ¢å¤
   - éªŒè¯é›†ç¾¤è‡ªåŠ¨é‡è¿æœºåˆ¶
   - éªŒè¯æ•°æ®ä¸€è‡´æ€§

4. **æé™æµ‹è¯•**
   - ç¡®å®šç³»ç»Ÿçš„æ•…éšœå®¹å¿é˜ˆå€¼
   - å‘ç°æ½œåœ¨çš„å•ç‚¹æ•…éšœ
   - éªŒè¯çº§è”æ•…éšœé˜²æŠ¤

### æˆåŠŸæ ‡å‡†

âœ… **å¿…é¡»æ»¡è¶³**:
- å•èŠ‚ç‚¹æ•…éšœä¸å½±å“æ•´ä½“æœåŠ¡å¯ç”¨æ€§
- æ¶ˆæ¯é›¶ä¸¢å¤±(QoS 1/2)
- ä¼šè¯çŠ¶æ€æ­£ç¡®æ¢å¤
- é›†ç¾¤è‡ªåŠ¨æ¢å¤åˆ°å¥åº·çŠ¶æ€

âš ï¸ **æœŸæœ›æ»¡è¶³**:
- RTO < 30ç§’
- æ•…éšœæœŸé—´æ¶ˆæ¯å»¶è¿Ÿ < 500ms (P99)
- ç½‘ç»œåˆ†åŒºæ¢å¤åæ•°æ®ä¸€è‡´

---

## æµ‹è¯•ç¯å¢ƒ

### Kubernetes é›†ç¾¤è¦æ±‚

```yaml
æœ€å°é…ç½®:
  èŠ‚ç‚¹æ•°: 3
  æ¯èŠ‚ç‚¹:
    CPU: 2 cores
    å†…å­˜: 4GB
    ç£ç›˜: 20GB
```

### EMQX-Go éƒ¨ç½²é…ç½®

```yaml
é›†ç¾¤é…ç½®:
  å‰¯æœ¬æ•°: 3
  èµ„æºé™åˆ¶:
    requests:
      cpu: "500m"
      memory: "512Mi"
    limits:
      cpu: "1000m"
      memory: "1Gi"
```

### ç›‘æ§ç»„ä»¶

- **Prometheus**: æŒ‡æ ‡æ”¶é›†
- **Grafana**: å¯è§†åŒ–ç›‘æ§
- **Loki**: æ—¥å¿—èšåˆ(å¯é€‰)

---

## Chaos Mesh å®‰è£…

### 1. ä½¿ç”¨ Helm å®‰è£…

```bash
# æ·»åŠ  Chaos Mesh ä»“åº“
helm repo add chaos-mesh https://charts.chaos-mesh.org
helm repo update

# åˆ›å»ºå‘½åç©ºé—´
kubectl create ns chaos-mesh

# å®‰è£… Chaos Mesh
helm install chaos-mesh chaos-mesh/chaos-mesh \
  --namespace=chaos-mesh \
  --set chaosDaemon.runtime=containerd \
  --set chaosDaemon.socketPath=/run/containerd/containerd.sock \
  --set dashboard.create=true \
  --version 2.6.0
```

### 2. éªŒè¯å®‰è£…

```bash
# æ£€æŸ¥ Chaos Mesh ç»„ä»¶çŠ¶æ€
kubectl get pods -n chaos-mesh

# è®¿é—® Chaos Dashboard (ç«¯å£è½¬å‘)
kubectl port-forward -n chaos-mesh svc/chaos-dashboard 2333:2333

# æµè§ˆå™¨è®¿é—®: http://localhost:2333
```

### 3. é…ç½® RBAC

```bash
# ä¸ºæµ‹è¯•å‘½åç©ºé—´åˆ›å»ºè§’è‰²ç»‘å®š
kubectl apply -f - <<EOF
apiVersion: v1
kind: ServiceAccount
metadata:
  name: chaos-test-sa
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: chaos-test-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: chaos-mesh-cluster-manager
subjects:
- kind: ServiceAccount
  name: chaos-test-sa
  namespace: default
EOF
```

---

## æµ‹è¯•åœºæ™¯

### åœºæ™¯åˆ†ç±»

æˆ‘ä»¬å°†æ··æ²Œæµ‹è¯•åˆ†ä¸ºä»¥ä¸‹å‡ ç±»åœºæ™¯:

#### ğŸ”´ é«˜ä¼˜å…ˆçº§åœºæ™¯ (P0)

è¿™äº›åœºæ™¯æ¨¡æ‹Ÿæœ€å¸¸è§ã€å½±å“æœ€å¤§çš„æ•…éšœ:

1. **Pod éšæœºæ•…éšœ** - æ¨¡æ‹ŸèŠ‚ç‚¹çªç„¶å®•æœº
2. **ç½‘ç»œåˆ†åŒº** - æ¨¡æ‹Ÿè„‘è£‚åœºæ™¯
3. **ç½‘ç»œå»¶è¿Ÿ** - æ¨¡æ‹Ÿç½‘ç»œæŠ–åŠ¨
4. **CPU å‹åŠ›** - æ¨¡æ‹Ÿé«˜è´Ÿè½½

#### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§åœºæ™¯ (P1)

è¿™äº›åœºæ™¯æ¨¡æ‹Ÿæ¬¡è¦ä½†ä»éœ€å…³æ³¨çš„æ•…éšœ:

5. **å†…å­˜å‹åŠ›** - æ¨¡æ‹Ÿå†…å­˜æ³„æ¼
6. **ç½‘ç»œä¸¢åŒ…** - æ¨¡æ‹Ÿä¸ç¨³å®šç½‘ç»œ
7. **ç£ç›˜ IO å‹åŠ›** - æ¨¡æ‹Ÿå­˜å‚¨ç“¶é¢ˆ
8. **æ—¶é’Ÿåç§»** - æ¨¡æ‹Ÿæ—¶é—´åŒæ­¥é—®é¢˜

#### ğŸŸ¢ ä½ä¼˜å…ˆçº§åœºæ™¯ (P2)

è¿™äº›åœºæ™¯æ¨¡æ‹Ÿç½•è§ä½†éœ€è¦è€ƒè™‘çš„æ•…éšœ:

9. **DNS æ•…éšœ** - æ¨¡æ‹ŸæœåŠ¡å‘ç°é—®é¢˜
10. **ç³»ç»Ÿè°ƒç”¨æ•…éšœ** - æ¨¡æ‹Ÿå†…æ ¸å¼‚å¸¸
11. **å®¹å™¨é‡å¯** - æ¨¡æ‹Ÿ OOM Killer
12. **ç½‘ç»œå¸¦å®½é™åˆ¶** - æ¨¡æ‹Ÿæ‹¥å¡

---

## æµ‹è¯•ç”¨ä¾‹

### æµ‹è¯•ç”¨ä¾‹ 1: Pod Kill - éšæœºèŠ‚ç‚¹æ•…éšœ

**ç›®æ ‡**: éªŒè¯é›†ç¾¤åœ¨å•èŠ‚ç‚¹çªç„¶æ•…éšœæ—¶çš„å¼¹æ€§

**åœºæ™¯æè¿°**:
- éšæœºæ€æ­»ä¸€ä¸ª EMQX-Go Pod
- è§‚å¯Ÿå…¶ä»–èŠ‚ç‚¹æ˜¯å¦æ­£å¸¸æ¥ç®¡æœåŠ¡
- éªŒè¯å®¢æˆ·ç«¯é‡è¿å’Œæ¶ˆæ¯è·¯ç”±

**Chaos é…ç½®**:

```yaml
# chaos/01-pod-kill.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: emqx-pod-kill
  namespace: default
spec:
  action: pod-kill
  mode: one
  selector:
    namespaces:
      - default
    labelSelectors:
      app: emqx-go
  scheduler:
    cron: '@every 5m'
  duration: '10s'
```

**é¢„æœŸç»“æœ**:
- âœ… å…¶ä»–èŠ‚ç‚¹ç»§ç»­æœåŠ¡
- âœ… å®¢æˆ·ç«¯è‡ªåŠ¨é‡è¿åˆ°å¥åº·èŠ‚ç‚¹
- âœ… æ¶ˆæ¯è·¯ç”±æ­£å¸¸
- âœ… Pod è‡ªåŠ¨é‡å¯å¹¶é‡æ–°åŠ å…¥é›†ç¾¤

**éªŒè¯æŒ‡æ ‡**:
```promql
# é›†ç¾¤å¯ç”¨æ€§
sum(up{job="emqx-go"}) / count(up{job="emqx-go"}) >= 0.66

# æ¶ˆæ¯ä¸¢å¤±ç‡
rate(emqx_messages_dropped_total[1m]) == 0

# é‡è¿æˆåŠŸç‡
rate(emqx_connections_success_total[1m]) > 0
```

**æµ‹è¯•æ­¥éª¤**:

```bash
# 1. éƒ¨ç½² EMQX-Go é›†ç¾¤
kubectl apply -f k8s/statefulset.yaml

# 2. å¯åŠ¨æµ‹è¯•è´Ÿè½½
./scripts/start-test-load.sh

# 3. åº”ç”¨æ··æ²Œ
kubectl apply -f chaos/01-pod-kill.yaml

# 4. ç›‘æ§æŒ‡æ ‡
kubectl port-forward svc/prometheus 9090:9090

# 5. ç­‰å¾…æµ‹è¯•ç»“æŸ
sleep 600  # 10åˆ†é’Ÿ

# 6. æ¸…ç†
kubectl delete -f chaos/01-pod-kill.yaml
```

---

### æµ‹è¯•ç”¨ä¾‹ 2: Network Partition - ç½‘ç»œåˆ†åŒº

**ç›®æ ‡**: éªŒè¯é›†ç¾¤åœ¨ç½‘ç»œåˆ†åŒº(è„‘è£‚)åœºæ™¯ä¸‹çš„è¡Œä¸º

**åœºæ™¯æè¿°**:
- å°†é›†ç¾¤åˆ†ä¸ºä¸¤ä¸ªåˆ†åŒº: Node1+Node2 vs Node3
- æ¨¡æ‹Ÿç½‘ç»œå®Œå…¨æ–­å¼€çš„æƒ…å†µ
- è§‚å¯Ÿè„‘è£‚æ£€æµ‹å’Œæ¢å¤æœºåˆ¶

**Chaos é…ç½®**:

```yaml
# chaos/02-network-partition.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: emqx-network-partition
  namespace: default
spec:
  action: partition
  mode: all
  selector:
    namespaces:
      - default
    labelSelectors:
      app: emqx-go
  direction: both
  target:
    mode: one
    selector:
      namespaces:
        - default
      labelSelectors:
        app: emqx-go
      podPhaseSelectors:
        - Running
  duration: '2m'
```

**é¢„æœŸç»“æœ**:
- âœ… å¤šæ•°æ´¾åˆ†åŒºç»§ç»­æœåŠ¡
- âœ… å°‘æ•°æ´¾åˆ†åŒºåœæ­¢æ¥å—æ–°è¿æ¥
- âœ… åˆ†åŒºæ¢å¤åè‡ªåŠ¨åˆå¹¶çŠ¶æ€
- âš ï¸ å¯èƒ½å‡ºç°çŸ­æš‚çš„æ¶ˆæ¯é‡å¤(QoS 1)

**éªŒè¯æŒ‡æ ‡**:
```promql
# æ£€æµ‹åˆ†åŒº
count(up{job="emqx-go"} == 1) < count(up{job="emqx-go"})

# æ¶ˆæ¯é‡å¤ç‡
rate(emqx_messages_duplicate_total[1m])

# é›†ç¾¤çŠ¶æ€ä¸ä¸€è‡´
emqx_cluster_inconsistent_nodes > 0
```

---

### æµ‹è¯•ç”¨ä¾‹ 3: Network Delay - ç½‘ç»œå»¶è¿Ÿ

**ç›®æ ‡**: éªŒè¯ç³»ç»Ÿåœ¨é«˜å»¶è¿Ÿç½‘ç»œç¯å¢ƒä¸‹çš„æ€§èƒ½

**åœºæ™¯æè¿°**:
- å¯¹é›†ç¾¤èŠ‚ç‚¹é—´é€šä¿¡æ³¨å…¥ 100ms-500ms å»¶è¿Ÿ
- æ¨¡æ‹Ÿè·¨åŒºåŸŸéƒ¨ç½²æˆ–ç½‘ç»œæ‹¥å¡
- è§‚å¯Ÿå¯¹æ¶ˆæ¯å»¶è¿Ÿå’Œååé‡çš„å½±å“

**Chaos é…ç½®**:

```yaml
# chaos/03-network-delay.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: emqx-network-delay
  namespace: default
spec:
  action: delay
  mode: all
  selector:
    namespaces:
      - default
    labelSelectors:
      app: emqx-go
  delay:
    latency: "250ms"
    correlation: "50"
    jitter: "100ms"
  direction: both
  duration: '5m'
```

**é¢„æœŸç»“æœ**:
- âœ… ç³»ç»Ÿä¿æŒå¯ç”¨
- âš ï¸ æ¶ˆæ¯å»¶è¿Ÿå¢åŠ  (< 1s P99)
- âš ï¸ ååé‡ä¸‹é™ (>= 70% æ­£å¸¸æ°´å¹³)
- âœ… æ— æ¶ˆæ¯ä¸¢å¤±

**éªŒè¯æŒ‡æ ‡**:
```promql
# æ¶ˆæ¯å»¶è¿Ÿ P99
histogram_quantile(0.99, rate(emqx_message_latency_bucket[1m]))

# ååé‡
rate(emqx_messages_sent_total[1m])
```

---

### æµ‹è¯•ç”¨ä¾‹ 4: CPU Stress - CPU å‹åŠ›æµ‹è¯•

**ç›®æ ‡**: éªŒè¯ç³»ç»Ÿåœ¨ CPU é«˜è´Ÿè½½ä¸‹çš„è¡Œä¸º

**åœºæ™¯æè¿°**:
- åœ¨ä¸€ä¸ªèŠ‚ç‚¹ä¸Šæ³¨å…¥ 80% CPU å‹åŠ›
- æŒç»­ 3 åˆ†é’Ÿ
- è§‚å¯Ÿ Actor ç³»ç»Ÿå’Œæ¶ˆæ¯å¤„ç†çš„å½±å“

**Chaos é…ç½®**:

```yaml
# chaos/04-cpu-stress.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: StressChaos
metadata:
  name: emqx-cpu-stress
  namespace: default
spec:
  mode: one
  selector:
    namespaces:
      - default
    labelSelectors:
      app: emqx-go
  stressors:
    cpu:
      workers: 2
      load: 80
  duration: '3m'
```

**é¢„æœŸç»“æœ**:
- âœ… ç³»ç»Ÿä¿æŒå“åº”
- âš ï¸ å—å½±å“èŠ‚ç‚¹çš„æ¶ˆæ¯å¤„ç†é€Ÿåº¦ä¸‹é™
- âœ… å…¶ä»–èŠ‚ç‚¹æ­£å¸¸å·¥ä½œ
- âœ… CPU å‹åŠ›æ¶ˆå¤±åå¿«é€Ÿæ¢å¤

**éªŒè¯æŒ‡æ ‡**:
```promql
# CPU ä½¿ç”¨ç‡
rate(process_cpu_seconds_total{job="emqx-go"}[1m]) * 100

# Goroutine æ•°é‡
go_goroutines{job="emqx-go"}

# Actor é‚®ç®±ç§¯å‹
emqx_actor_mailbox_size
```

---

### æµ‹è¯•ç”¨ä¾‹ 5: Memory Stress - å†…å­˜å‹åŠ›æµ‹è¯•

**ç›®æ ‡**: éªŒè¯ç³»ç»Ÿåœ¨å†…å­˜å‹åŠ›ä¸‹çš„è¡Œä¸ºå’Œ OOM å¤„ç†

**åœºæ™¯æè¿°**:
- åœ¨ä¸€ä¸ªèŠ‚ç‚¹ä¸Šåˆ†é…å¤§é‡å†…å­˜
- è§‚å¯Ÿæ˜¯å¦è§¦å‘ OOM Killer
- éªŒè¯ Pod é‡å¯åçš„æ¢å¤

**Chaos é…ç½®**:

```yaml
# chaos/05-memory-stress.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: StressChaos
metadata:
  name: emqx-memory-stress
  namespace: default
spec:
  mode: one
  selector:
    namespaces:
      - default
    labelSelectors:
      app: emqx-go
  stressors:
    memory:
      workers: 4
      size: '512MB'
  duration: '3m'
```

**é¢„æœŸç»“æœ**:
- âœ… å†…å­˜ä½¿ç”¨è§¦å‘ K8s é™åˆ¶
- âœ… Pod è¢« OOM Killer ç»ˆæ­¢åè‡ªåŠ¨é‡å¯
- âœ… é‡å¯åé‡æ–°åŠ å…¥é›†ç¾¤
- âœ… æŒä¹…åŒ–ä¼šè¯æ¢å¤

**éªŒè¯æŒ‡æ ‡**:
```promql
# å†…å­˜ä½¿ç”¨ç‡
process_resident_memory_bytes{job="emqx-go"} / 1024 / 1024

# OOM é‡å¯æ¬¡æ•°
kube_pod_container_status_restarts_total{pod=~"emqx-go.*"}

# ä¼šè¯æ¢å¤
emqx_sessions_count
```

---

### æµ‹è¯•ç”¨ä¾‹ 6: Network Loss - ç½‘ç»œä¸¢åŒ…

**ç›®æ ‡**: éªŒè¯ç³»ç»Ÿåœ¨ä¸¢åŒ…ç¯å¢ƒä¸‹çš„é‡ä¼ æœºåˆ¶

**åœºæ™¯æè¿°**:
- æ³¨å…¥ 20% ç½‘ç»œä¸¢åŒ…ç‡
- è§‚å¯Ÿ TCP é‡ä¼ å’Œæ¶ˆæ¯å¯é æ€§
- éªŒè¯ gRPC è¿æ¥çš„ç¨³å®šæ€§

**Chaos é…ç½®**:

```yaml
# chaos/06-network-loss.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: emqx-network-loss
  namespace: default
spec:
  action: loss
  mode: all
  selector:
    namespaces:
      - default
    labelSelectors:
      app: emqx-go
  loss:
    loss: '20'
    correlation: '25'
  direction: both
  duration: '5m'
```

**é¢„æœŸç»“æœ**:
- âœ… TCP å±‚è‡ªåŠ¨é‡ä¼ 
- âœ… æ¶ˆæ¯æœ€ç»ˆé€è¾¾
- âš ï¸ å»¶è¿Ÿå¢åŠ 
- âš ï¸ å¯èƒ½è§¦å‘è¿æ¥è¶…æ—¶å’Œé‡è¿

**éªŒè¯æŒ‡æ ‡**:
```promql
# TCP é‡ä¼ ç‡
rate(node_netstat_Tcp_RetransSegs[1m]) / rate(node_netstat_Tcp_OutSegs[1m])

# è¿æ¥æ–­å¼€
rate(emqx_connections_closed_total[1m])
```

---

### æµ‹è¯•ç”¨ä¾‹ 7: IO Stress - ç£ç›˜ IO å‹åŠ›

**ç›®æ ‡**: éªŒè¯ç³»ç»Ÿåœ¨ç£ç›˜ IO å‹åŠ›ä¸‹çš„æ€§èƒ½

**åœºæ™¯æè¿°**:
- å¯¹èŠ‚ç‚¹æ³¨å…¥é«˜é¢‘ç£ç›˜è¯»å†™
- è§‚å¯Ÿå¯¹ä¼šè¯æŒä¹…åŒ–çš„å½±å“
- è¯„ä¼°æ€§èƒ½é™çº§ç¨‹åº¦

**Chaos é…ç½®**:

```yaml
# chaos/07-io-stress.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: IOChaos
metadata:
  name: emqx-io-stress
  namespace: default
spec:
  action: mixed-read-write
  mode: one
  selector:
    namespaces:
      - default
    labelSelectors:
      app: emqx-go
  volumePath: /data
  path: '/data/**/*'
  percent: 50
  duration: '3m'
  delay: '100ms'
```

**é¢„æœŸç»“æœ**:
- âœ… ç³»ç»Ÿä¿æŒå¯ç”¨
- âš ï¸ æŒä¹…åŒ–æ“ä½œå»¶è¿Ÿå¢åŠ 
- âš ï¸ æ•´ä½“ååé‡ä¸‹é™
- âœ… IO å‹åŠ›æ¶ˆå¤±åæ¢å¤æ­£å¸¸

---

### æµ‹è¯•ç”¨ä¾‹ 8: Time Skew - æ—¶é’Ÿåç§»

**ç›®æ ‡**: éªŒè¯ç³»ç»Ÿå¯¹æ—¶é—´ä¸åŒæ­¥çš„å®¹å¿åº¦

**åœºæ™¯æè¿°**:
- å°†ä¸€ä¸ªèŠ‚ç‚¹çš„æ—¶é’Ÿå‘å‰åç§» 5 åˆ†é’Ÿ
- è§‚å¯Ÿå¯¹è¶…æ—¶åˆ¤æ–­å’Œæ¶ˆæ¯æ—¶é—´æˆ³çš„å½±å“
- éªŒè¯ä¼šè¯è¿‡æœŸé€»è¾‘

**Chaos é…ç½®**:

```yaml
# chaos/08-time-skew.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: TimeChaos
metadata:
  name: emqx-time-skew
  namespace: default
spec:
  mode: one
  selector:
    namespaces:
      - default
    labelSelectors:
      app: emqx-go
  timeOffset: '5m'
  clockIds:
    - CLOCK_REALTIME
  duration: '2m'
```

**é¢„æœŸç»“æœ**:
- âš ï¸ å¯èƒ½å‡ºç°è¶…æ—¶åˆ¤æ–­å¼‚å¸¸
- âš ï¸ æ¶ˆæ¯æ—¶é—´æˆ³ä¸ä¸€è‡´
- âœ… ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½
- âœ… æ—¶é’Ÿæ¢å¤åè‡ªåŠ¨ä¿®æ­£

---

### æµ‹è¯•ç”¨ä¾‹ 9: DNS Failure - DNS æ•…éšœ

**ç›®æ ‡**: éªŒè¯ DNS è§£æå¤±è´¥å¯¹æœåŠ¡å‘ç°çš„å½±å“

**åœºæ™¯æè¿°**:
- ä½¿ DNS æŸ¥è¯¢éšæœºå¤±è´¥
- è§‚å¯ŸèŠ‚ç‚¹å‘ç°å’Œé‡è¿æœºåˆ¶
- éªŒè¯ DNS ç¼“å­˜çš„ä½œç”¨

**Chaos é…ç½®**:

```yaml
# chaos/09-dns-failure.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: DNSChaos
metadata:
  name: emqx-dns-failure
  namespace: default
spec:
  action: random
  mode: all
  selector:
    namespaces:
      - default
    labelSelectors:
      app: emqx-go
  patterns:
    - emqx-go-*
    - '*.emqx-go-headless.default.svc.cluster.local'
  duration: '2m'
```

**é¢„æœŸç»“æœ**:
- âœ… å·²å»ºç«‹çš„è¿æ¥ä¸å—å½±å“
- âš ï¸ æ–°èŠ‚ç‚¹åŠ å…¥å¤±è´¥
- âœ… DNS æ¢å¤åè‡ªåŠ¨é‡è¯•æˆåŠŸ
- âš ï¸ å¯èƒ½å½±å“ K8s æœåŠ¡å‘ç°

---

### æµ‹è¯•ç”¨ä¾‹ 10: Container Kill - å®¹å™¨çº§æ•…éšœ

**ç›®æ ‡**: éªŒè¯å®¹å™¨å±‚é¢æ•…éšœçš„æ¢å¤èƒ½åŠ›

**åœºæ™¯æè¿°**:
- æ€æ­»å®¹å™¨è¿›ç¨‹ä½†ä¸åˆ é™¤ Pod
- è§‚å¯Ÿ K8s é‡å¯å®¹å™¨
- éªŒè¯å¿«é€Ÿæ¢å¤

**Chaos é…ç½®**:

```yaml
# chaos/10-container-kill.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: emqx-container-kill
  namespace: default
spec:
  action: container-kill
  mode: fixed
  value: '1'
  selector:
    namespaces:
      - default
    labelSelectors:
      app: emqx-go
  containerNames:
    - emqx-go
  duration: '30s'
```

**é¢„æœŸç»“æœ**:
- âœ… å®¹å™¨è‡ªåŠ¨é‡å¯
- âœ… é‡å¯æ—¶é—´ < 10s
- âœ… çŠ¶æ€å¿«é€Ÿæ¢å¤
- âœ… æœ€å°åŒ–æœåŠ¡ä¸­æ–­

---

## ç›‘æ§ä¸éªŒè¯

### å…³é”®æŒ‡æ ‡

#### 1. å¯ç”¨æ€§æŒ‡æ ‡

```promql
# é›†ç¾¤æ•´ä½“å¯ç”¨æ€§ (è‡³å°‘ 2/3 èŠ‚ç‚¹åœ¨çº¿)
(sum(up{job="emqx-go"}) / count(up{job="emqx-go"})) >= 0.66

# æœåŠ¡å“åº”æˆåŠŸç‡
sum(rate(http_requests_total{status="200"}[1m]))
/
sum(rate(http_requests_total[1m])) > 0.99
```

#### 2. æ€§èƒ½æŒ‡æ ‡

```promql
# æ¶ˆæ¯å»¶è¿Ÿ P50, P95, P99
histogram_quantile(0.50, rate(emqx_message_latency_bucket[1m]))
histogram_quantile(0.95, rate(emqx_message_latency_bucket[1m]))
histogram_quantile(0.99, rate(emqx_message_latency_bucket[1m]))

# æ¶ˆæ¯ååé‡
sum(rate(emqx_messages_sent_total[1m]))
sum(rate(emqx_messages_received_total[1m]))
```

#### 3. å¯é æ€§æŒ‡æ ‡

```promql
# æ¶ˆæ¯ä¸¢å¤±ç‡ (åº”è¯¥ä¸º 0)
rate(emqx_messages_dropped_total[1m])

# è¿æ¥æ–­å¼€ç‡
rate(emqx_connections_closed_total{reason="error"}[1m])

# Actor é‡å¯æ¬¡æ•°
rate(emqx_actor_restarts_total[1m])
```

#### 4. èµ„æºæŒ‡æ ‡

```promql
# CPU ä½¿ç”¨ç‡
rate(process_cpu_seconds_total{job="emqx-go"}[1m]) * 100

# å†…å­˜ä½¿ç”¨
process_resident_memory_bytes{job="emqx-go"} / 1024 / 1024

# Goroutine æ•°é‡
go_goroutines{job="emqx-go"}

# GC æš‚åœæ—¶é—´
rate(go_gc_duration_seconds_sum[1m])
```

### Grafana ä»ªè¡¨æ¿

åˆ›å»ºä¸€ä¸ªä¸“é—¨çš„æ··æ²Œæµ‹è¯•ä»ªè¡¨æ¿:

```json
{
  "dashboard": {
    "title": "EMQX-Go Chaos Testing",
    "panels": [
      {
        "title": "Cluster Health",
        "targets": [
          {"expr": "sum(up{job=\"emqx-go\"})"}
        ]
      },
      {
        "title": "Message Latency (P99)",
        "targets": [
          {"expr": "histogram_quantile(0.99, rate(emqx_message_latency_bucket[1m]))"}
        ]
      },
      {
        "title": "Message Loss Rate",
        "targets": [
          {"expr": "rate(emqx_messages_dropped_total[1m])"}
        ]
      },
      {
        "title": "Actor Restarts",
        "targets": [
          {"expr": "rate(emqx_actor_restarts_total[1m])"}
        ]
      }
    ]
  }
}
```

### æ—¥å¿—èšåˆ

ä½¿ç”¨ Loki æ”¶é›†å’ŒæŸ¥è¯¢æ—¥å¿—:

```bash
# æŸ¥è¯¢æ•…éšœæœŸé—´çš„é”™è¯¯æ—¥å¿—
{app="emqx-go"} |= "error" |= "chaos"

# æŸ¥è¯¢ Actor é‡å¯æ—¥å¿—
{app="emqx-go"} |= "Actor.*restarted"

# æŸ¥è¯¢é›†ç¾¤çŠ¶æ€å˜åŒ–
{app="emqx-go"} |= "cluster" |= "join\|leave\|partition"
```

---

## æ‰§è¡Œè®¡åˆ’

### æµ‹è¯•é˜¶æ®µ

#### é˜¶æ®µ 1: å‡†å¤‡é˜¶æ®µ (Day 1-2)

**ç›®æ ‡**: æ­å»ºæµ‹è¯•ç¯å¢ƒ

- [ ] éƒ¨ç½² Kubernetes é›†ç¾¤
- [ ] å®‰è£… Chaos Mesh
- [ ] éƒ¨ç½² EMQX-Go (3 èŠ‚ç‚¹)
- [ ] é…ç½® Prometheus + Grafana
- [ ] å‡†å¤‡æµ‹è¯•è„šæœ¬å’Œè´Ÿè½½ç”Ÿæˆå™¨
- [ ] å»ºç«‹åŸºçº¿æŒ‡æ ‡

#### é˜¶æ®µ 2: å†’çƒŸæµ‹è¯• (Day 3)

**ç›®æ ‡**: éªŒè¯æµ‹è¯•åŸºç¡€è®¾æ–½

- [ ] è¿è¡Œæµ‹è¯•ç”¨ä¾‹ 1 (Pod Kill) - çŸ­æ—¶é—´
- [ ] éªŒè¯ç›‘æ§ç³»ç»Ÿå·¥ä½œæ­£å¸¸
- [ ] éªŒè¯æŒ‡æ ‡æ”¶é›†å®Œæ•´
- [ ] è°ƒæ•´æµ‹è¯•å‚æ•°

#### é˜¶æ®µ 3: P0 æµ‹è¯• (Day 4-6)

**ç›®æ ‡**: æ‰§è¡Œé«˜ä¼˜å…ˆçº§æµ‹è¯•

- [ ] æµ‹è¯•ç”¨ä¾‹ 1: Pod Kill
- [ ] æµ‹è¯•ç”¨ä¾‹ 2: Network Partition
- [ ] æµ‹è¯•ç”¨ä¾‹ 3: Network Delay
- [ ] æµ‹è¯•ç”¨ä¾‹ 4: CPU Stress
- [ ] æ”¶é›†å’Œåˆ†æç»“æœ
- [ ] ä¿®å¤å‘ç°çš„é—®é¢˜

#### é˜¶æ®µ 4: P1 æµ‹è¯• (Day 7-9)

**ç›®æ ‡**: æ‰§è¡Œä¸­ä¼˜å…ˆçº§æµ‹è¯•

- [ ] æµ‹è¯•ç”¨ä¾‹ 5: Memory Stress
- [ ] æµ‹è¯•ç”¨ä¾‹ 6: Network Loss
- [ ] æµ‹è¯•ç”¨ä¾‹ 7: IO Stress
- [ ] æµ‹è¯•ç”¨ä¾‹ 8: Time Skew
- [ ] æ”¶é›†å’Œåˆ†æç»“æœ

#### é˜¶æ®µ 5: P2 æµ‹è¯• (Day 10-11)

**ç›®æ ‡**: æ‰§è¡Œä½ä¼˜å…ˆçº§æµ‹è¯•

- [ ] æµ‹è¯•ç”¨ä¾‹ 9: DNS Failure
- [ ] æµ‹è¯•ç”¨ä¾‹ 10: Container Kill
- [ ] ç»„åˆåœºæ™¯æµ‹è¯•
- [ ] æé™æµ‹è¯•

#### é˜¶æ®µ 6: æ€»ç»“é˜¶æ®µ (Day 12-14)

**ç›®æ ‡**: æ•´ç†ç»“æœå’Œæ”¹è¿›

- [ ] æ±‡æ€»æ‰€æœ‰æµ‹è¯•ç»“æœ
- [ ] ç¼–å†™æµ‹è¯•æŠ¥å‘Š
- [ ] ä¼˜å…ˆçº§æ’åºå‘ç°çš„é—®é¢˜
- [ ] åˆ¶å®šæ”¹è¿›è®¡åˆ’
- [ ] æ›´æ–°æ–‡æ¡£

### æµ‹è¯•æ—¶é—´è¡¨

```
Week 1:
  Mon-Tue:  ç¯å¢ƒå‡†å¤‡
  Wed:      å†’çƒŸæµ‹è¯•
  Thu-Fri:  P0 æµ‹è¯•

Week 2:
  Mon-Wed:  P1 æµ‹è¯•
  Thu:      P2 æµ‹è¯•
  Fri:      æ€»ç»“æŠ¥å‘Š
```

### è´Ÿè½½æ¨¡å¼

åœ¨æ··æ²Œæµ‹è¯•æœŸé—´,ä¿æŒä»¥ä¸‹è´Ÿè½½:

```yaml
æµ‹è¯•è´Ÿè½½:
  MQTT å®¢æˆ·ç«¯: 1000 ä¸ªè¿æ¥
  æ¶ˆæ¯å‘å¸ƒé€Ÿç‡: 100 msg/s
  è®¢é˜…ä¸»é¢˜æ•°: 50 ä¸ª
  æ¶ˆæ¯å¤§å°: 256 bytes
  QoS åˆ†å¸ƒ:
    QoS 0: 40%
    QoS 1: 50%
    QoS 2: 10%
```

---

## æ•…éšœæ¢å¤éªŒè¯

### è‡ªåŠ¨æ¢å¤æ£€æŸ¥æ¸…å•

æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹éƒ½åº”éªŒè¯ä»¥ä¸‹æ¢å¤æŒ‡æ ‡:

#### âœ… é›†ç¾¤çº§åˆ«

- [ ] **é›†ç¾¤æˆå‘˜**: æ‰€æœ‰èŠ‚ç‚¹é‡æ–°åŠ å…¥é›†ç¾¤
- [ ] **è·¯ç”±è¡¨**: è®¢é˜…è·¯ç”±æ­£ç¡®åŒæ­¥
- [ ] **å¥åº·æ£€æŸ¥**: æ‰€æœ‰å¥åº·æ£€æŸ¥é€šè¿‡
- [ ] **æ€§èƒ½æŒ‡æ ‡**: æ¢å¤åˆ°åŸºçº¿çš„ 90%+

#### âœ… èŠ‚ç‚¹çº§åˆ«

- [ ] **è¿›ç¨‹çŠ¶æ€**: æ‰€æœ‰è¿›ç¨‹æ­£å¸¸è¿è¡Œ
- [ ] **ç«¯å£ç›‘å¬**: MQTT/gRPC ç«¯å£æ­£å¸¸ç›‘å¬
- [ ] **èµ„æºä½¿ç”¨**: CPU/å†…å­˜åœ¨æ­£å¸¸èŒƒå›´
- [ ] **æ—¥å¿—æ­£å¸¸**: æ— æŒç»­é”™è¯¯æ—¥å¿—

#### âœ… åº”ç”¨çº§åˆ«

- [ ] **è¿æ¥çŠ¶æ€**: å®¢æˆ·ç«¯æˆåŠŸé‡è¿
- [ ] **ä¼šè¯æ¢å¤**: æŒä¹…åŒ–ä¼šè¯æ­£ç¡®æ¢å¤
- [ ] **æ¶ˆæ¯è·¯ç”±**: æ¶ˆæ¯æ­£ç¡®è·¯ç”±åˆ°è®¢é˜…è€…
- [ ] **QoS ä¿è¯**: QoS 1/2 æ¶ˆæ¯ä¸ä¸¢å¤±

#### âœ… æ•°æ®çº§åˆ«

- [ ] **æ¶ˆæ¯å®Œæ•´æ€§**: æ— æ¶ˆæ¯ä¸¢å¤±
- [ ] **æ¶ˆæ¯é¡ºåº**: å•å®¢æˆ·ç«¯æ¶ˆæ¯é¡ºåºæ­£ç¡®
- [ ] **ä¼šè¯çŠ¶æ€**: è®¢é˜…ä¿¡æ¯æ­£ç¡®ä¿å­˜
- [ ] **Retained æ¶ˆæ¯**: Retained æ¶ˆæ¯æ­£ç¡®ä¿ç•™

### æ¢å¤æ—¶é—´ç›®æ ‡ (RTO)

| æ•…éšœç±»å‹ | ç›®æ ‡ RTO | å¯æ¥å— RTO |
|---------|---------|-----------|
| Pod Kill | < 10s | < 30s |
| Container Kill | < 5s | < 15s |
| Network Partition | < 30s | < 60s |
| èŠ‚ç‚¹æ•…éšœ | < 60s | < 120s |

### æ¢å¤éªŒè¯è„šæœ¬

```bash
#!/bin/bash
# chaos/verify-recovery.sh

echo "=== Verifying EMQX-Go Recovery ==="

# 1. æ£€æŸ¥æ‰€æœ‰ Pod è¿è¡Œ
echo "Checking Pod status..."
READY_PODS=$(kubectl get pods -l app=emqx-go -o json | \
  jq '[.items[] | select(.status.phase=="Running")] | length')
TOTAL_PODS=$(kubectl get pods -l app=emqx-go --no-headers | wc -l)

if [ "$READY_PODS" -eq "$TOTAL_PODS" ]; then
  echo "âœ“ All pods are running ($READY_PODS/$TOTAL_PODS)"
else
  echo "âœ— Some pods are not running ($READY_PODS/$TOTAL_PODS)"
  exit 1
fi

# 2. æ£€æŸ¥æœåŠ¡ç«¯å£
echo "Checking service endpoints..."
MQTT_ENDPOINTS=$(kubectl get endpoints emqx-go-mqtt -o json | \
  jq '.subsets[].addresses | length')

if [ "$MQTT_ENDPOINTS" -ge 2 ]; then
  echo "âœ“ MQTT endpoints available: $MQTT_ENDPOINTS"
else
  echo "âœ— Insufficient MQTT endpoints: $MQTT_ENDPOINTS"
  exit 1
fi

# 3. æµ‹è¯• MQTT è¿æ¥
echo "Testing MQTT connectivity..."
timeout 10 mosquitto_pub -h localhost -p 1883 \
  -t "chaos/test" -m "recovery-test" -q 1 \
  -u test -P test

if [ $? -eq 0 ]; then
  echo "âœ“ MQTT publish successful"
else
  echo "âœ— MQTT publish failed"
  exit 1
fi

# 4. æ£€æŸ¥ Prometheus æŒ‡æ ‡
echo "Checking Prometheus metrics..."
METRICS=$(curl -s http://localhost:9090/api/v1/query \
  --data-urlencode 'query=up{job="emqx-go"}' | \
  jq '.data.result | length')

if [ "$METRICS" -ge 2 ]; then
  echo "âœ“ Prometheus metrics available: $METRICS"
else
  echo "âœ— Insufficient metrics: $METRICS"
  exit 1
fi

# 5. æ£€æŸ¥é”™è¯¯æ—¥å¿—
echo "Checking for error logs..."
ERROR_COUNT=$(kubectl logs -l app=emqx-go --tail=100 | \
  grep -i "error\|fatal\|panic" | wc -l)

if [ "$ERROR_COUNT" -lt 5 ]; then
  echo "âœ“ Low error count: $ERROR_COUNT"
else
  echo "âš  High error count: $ERROR_COUNT (review logs)"
fi

echo ""
echo "=== Recovery Verification Complete ==="
echo "âœ“ All checks passed"
```

---

## é™„å½•

### A. å¿«é€Ÿå¼€å§‹æŒ‡å—

```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/turtacn/emqx-go.git
cd emqx-go

# 2. åˆ›å»ºæ··æ²Œæµ‹è¯•ç›®å½•
mkdir -p chaos

# 3. ä¿å­˜æ‰€æœ‰ chaos yaml æ–‡ä»¶åˆ° chaos/ ç›®å½•

# 4. éƒ¨ç½² EMQX-Go
kubectl apply -f k8s/

# 5. ç­‰å¾… Pod å°±ç»ª
kubectl wait --for=condition=ready pod -l app=emqx-go --timeout=300s

# 6. è¿è¡Œç¬¬ä¸€ä¸ªæ··æ²Œæµ‹è¯•
kubectl apply -f chaos/01-pod-kill.yaml

# 7. ç›‘æ§æµ‹è¯•
kubectl get podchaos -w

# 8. æŸ¥çœ‹ç»“æœ
kubectl logs -l app=emqx-go --tail=100

# 9. æ¸…ç†
kubectl delete -f chaos/01-pod-kill.yaml
```

### B. æ•…éšœæ’æŸ¥

#### é—®é¢˜: Chaos å®éªŒæœªç”Ÿæ•ˆ

**åŸå› **:
- RBAC æƒé™ä¸è¶³
- é€‰æ‹©å™¨åŒ¹é…ä¸åˆ° Pod
- Chaos Daemon æœªè¿è¡Œ

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ Chaos Mesh çŠ¶æ€
kubectl get pods -n chaos-mesh

# æŸ¥çœ‹å®éªŒçŠ¶æ€
kubectl describe podchaos emqx-pod-kill

# æ£€æŸ¥äº‹ä»¶
kubectl get events --sort-by='.lastTimestamp'
```

#### é—®é¢˜: æµ‹è¯•åç³»ç»Ÿæœªæ¢å¤

**åŸå› **:
- Duration è®¾ç½®è¿‡é•¿
- Pod é‡å¯å¤±è´¥
- èµ„æºé…é¢é™åˆ¶

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ‰‹åŠ¨åˆ é™¤ Chaos å®éªŒ
kubectl delete podchaos --all
kubectl delete networkchaos --all
kubectl delete stresschaos --all

# é‡å¯ Pod
kubectl rollout restart statefulset emqx-go

# æ£€æŸ¥èµ„æº
kubectl describe node
```

#### é—®é¢˜: ç›‘æ§æŒ‡æ ‡ç¼ºå¤±

**åŸå› **:
- ServiceMonitor é…ç½®é”™è¯¯
- Prometheus æœªæŠ“å–æŒ‡æ ‡
- ç½‘ç»œç­–ç•¥é˜»æ­¢

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ Prometheus targets
kubectl port-forward -n monitoring svc/prometheus 9090:9090
# è®¿é—® http://localhost:9090/targets

# æµ‹è¯•æŒ‡æ ‡ç«¯ç‚¹
kubectl exec -it emqx-go-0 -- curl localhost:8082/metrics

# æ£€æŸ¥ ServiceMonitor
kubectl get servicemonitor -A
```

### C. æµ‹è¯•è´Ÿè½½ç”Ÿæˆå™¨

åˆ›å»ºä¸€ä¸ªç®€å•çš„ MQTT è´Ÿè½½ç”Ÿæˆå™¨:

```go
// chaos/load-generator/main.go
package main

import (
    "fmt"
    "log"
    "sync"
    "time"

    mqtt "github.com/eclipse/paho.mqtt.golang"
)

type LoadConfig struct {
    Broker      string
    ClientCount int
    MsgRate     int // messages per second
    Topics      []string
}

func main() {
    config := LoadConfig{
        Broker:      "tcp://localhost:1883",
        ClientCount: 100,
        MsgRate:     10,
        Topics:      []string{"test/topic1", "test/topic2", "test/topic3"},
    }

    var wg sync.WaitGroup

    // å¯åŠ¨è®¢é˜…è€…
    for i := 0; i < config.ClientCount/2; i++ {
        wg.Add(1)
        go startSubscriber(&wg, config, i)
    }

    // å¯åŠ¨å‘å¸ƒè€…
    for i := 0; i < config.ClientCount/2; i++ {
        wg.Add(1)
        go startPublisher(&wg, config, i)
    }

    wg.Wait()
}

func startSubscriber(wg *sync.WaitGroup, config LoadConfig, id int) {
    defer wg.Done()

    opts := mqtt.NewClientOptions()
    opts.AddBroker(config.Broker)
    opts.SetClientID(fmt.Sprintf("sub-%d", id))
    opts.SetUsername("test")
    opts.SetPassword("test")
    opts.SetAutoReconnect(true)

    client := mqtt.NewClient(opts)
    if token := client.Connect(); token.Wait() && token.Error() != nil {
        log.Printf("Subscriber %d failed to connect: %v", id, token.Error())
        return
    }

    for _, topic := range config.Topics {
        if token := client.Subscribe(topic, 1, nil); token.Wait() && token.Error() != nil {
            log.Printf("Subscriber %d failed to subscribe to %s: %v", id, topic, token.Error())
        }
    }

    log.Printf("Subscriber %d connected and subscribed", id)

    // ä¿æŒè¿è¡Œ
    select {}
}

func startPublisher(wg *sync.WaitGroup, config LoadConfig, id int) {
    defer wg.Done()

    opts := mqtt.NewClientOptions()
    opts.AddBroker(config.Broker)
    opts.SetClientID(fmt.Sprintf("pub-%d", id))
    opts.SetUsername("test")
    opts.SetPassword("test")
    opts.SetAutoReconnect(true)

    client := mqtt.NewClient(opts)
    if token := client.Connect(); token.Wait() && token.Error() != nil {
        log.Printf("Publisher %d failed to connect: %v", id, token.Error())
        return
    }

    log.Printf("Publisher %d connected", id)

    ticker := time.NewTicker(time.Second / time.Duration(config.MsgRate))
    defer ticker.Stop()

    msgCount := 0
    for range ticker.C {
        topic := config.Topics[msgCount%len(config.Topics)]
        payload := fmt.Sprintf("msg-%d-%d-%d", id, msgCount, time.Now().Unix())

        token := client.Publish(topic, 1, false, payload)
        if token.Wait() && token.Error() != nil {
            log.Printf("Publisher %d failed to publish: %v", id, token.Error())
        }

        msgCount++
    }
}
```

### D. è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬

```bash
#!/bin/bash
# chaos/run-all-tests.sh

set -e

CHAOS_FILES=(
  "01-pod-kill.yaml"
  "02-network-partition.yaml"
  "03-network-delay.yaml"
  "04-cpu-stress.yaml"
  "05-memory-stress.yaml"
  "06-network-loss.yaml"
  "07-io-stress.yaml"
  "08-time-skew.yaml"
  "09-dns-failure.yaml"
  "10-container-kill.yaml"
)

RESULTS_DIR="chaos-results-$(date +%Y%m%d-%H%M%S)"
mkdir -p "$RESULTS_DIR"

echo "=== Starting Chaos Testing Suite ==="
echo "Results will be saved to: $RESULTS_DIR"

for chaos_file in "${CHAOS_FILES[@]}"; do
  TEST_NAME=$(basename "$chaos_file" .yaml)
  echo ""
  echo "========================================"
  echo "Running: $TEST_NAME"
  echo "========================================"

  # åº”ç”¨æ··æ²Œ
  kubectl apply -f "chaos/$chaos_file"

  # ç­‰å¾…æµ‹è¯•å®Œæˆ (æ ¹æ® duration + buffer)
  sleep 420  # 7åˆ†é’Ÿ

  # æ”¶é›†ç»“æœ
  echo "Collecting metrics..."
  kubectl get pods -l app=emqx-go -o wide > "$RESULTS_DIR/${TEST_NAME}-pods.txt"
  kubectl logs -l app=emqx-go --tail=500 > "$RESULTS_DIR/${TEST_NAME}-logs.txt"

  # éªŒè¯æ¢å¤
  echo "Verifying recovery..."
  ./chaos/verify-recovery.sh > "$RESULTS_DIR/${TEST_NAME}-recovery.txt" 2>&1

  if [ $? -eq 0 ]; then
    echo "âœ“ Test passed"
  else
    echo "âœ— Test failed - check logs"
  fi

  # æ¸…ç†
  kubectl delete -f "chaos/$chaos_file"

  # ç­‰å¾…ç³»ç»Ÿç¨³å®š
  sleep 60
done

echo ""
echo "=== Chaos Testing Complete ==="
echo "Results saved to: $RESULTS_DIR"
```

### E. å‚è€ƒèµ„æ–™

#### å®˜æ–¹æ–‡æ¡£

- [Chaos Mesh Documentation](https://chaos-mesh.org/docs/)
- [Kubernetes Best Practices](https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/)
- [MQTT Protocol Specification](https://mqtt.org/mqtt-specification/)

#### ç›¸å…³æ–‡ç« 

- [Principles of Chaos Engineering](https://principlesofchaos.org/)
- [Testing Microservices with Chaos Engineering](https://www.oreilly.com/library/view/chaos-engineering/9781492043850/)

#### å·¥å…·

- [Prometheus](https://prometheus.io/) - ç›‘æ§å’Œå‘Šè­¦
- [Grafana](https://grafana.com/) - å¯è§†åŒ–
- [MQTTX](https://mqttx.app/) - MQTT å®¢æˆ·ç«¯
- [K9s](https://k9scli.io/) - Kubernetes CLI

---

## æ€»ç»“

æœ¬æ··æ²Œæµ‹è¯•è®¡åˆ’ä¸º EMQX-Go ç³»ç»Ÿæä¾›äº†ä¸€ä¸ªå…¨é¢çš„å¼¹æ€§æµ‹è¯•æ¡†æ¶ã€‚é€šè¿‡ç³»ç»Ÿæ€§åœ°æ³¨å…¥å„ç§æ•…éšœ,æˆ‘ä»¬å¯ä»¥:

1. **éªŒè¯ç³»ç»Ÿçš„å®¹é”™èƒ½åŠ›** - ç¡®ä¿åœ¨æ•…éšœæƒ…å†µä¸‹ç³»ç»Ÿä»ç„¶å¯ç”¨
2. **å‘ç°æ½œåœ¨é—®é¢˜** - åœ¨ç”Ÿäº§ç¯å¢ƒå‡ºç°é—®é¢˜ä¹‹å‰å‘ç°è–„å¼±ç¯èŠ‚
3. **å»ºç«‹ä¿¡å¿ƒ** - é€šè¿‡æµ‹è¯•è¯æ˜ç³»ç»Ÿçš„å¯é æ€§
4. **æŒç»­æ”¹è¿›** - åŸºäºæµ‹è¯•ç»“æœä¸æ–­ä¼˜åŒ–ç³»ç»Ÿæ¶æ„

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. âœ… æŒ‰ç…§æœ¬æ–‡æ¡£éƒ¨ç½²æµ‹è¯•ç¯å¢ƒ
2. âœ… æ‰§è¡Œå†’çƒŸæµ‹è¯•éªŒè¯åŸºç¡€è®¾æ–½
3. âœ… æŒ‰ä¼˜å…ˆçº§æ‰§è¡Œæµ‹è¯•ç”¨ä¾‹
4. âœ… åˆ†æç»“æœå¹¶ä¿®å¤å‘ç°çš„é—®é¢˜
5. âœ… å°†æ··æ²Œæµ‹è¯•é›†æˆåˆ° CI/CD æµç¨‹

### æŒç»­è¿­ä»£

æ··æ²Œå·¥ç¨‹æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹,å»ºè®®:

- **å®šæœŸæ‰§è¡Œ**: æ¯æœˆæ‰§è¡Œä¸€æ¬¡å®Œæ•´æµ‹è¯•å¥—ä»¶
- **æ–°åœºæ™¯**: æ ¹æ®ç”Ÿäº§äº‹æ•…è¡¥å……æ–°çš„æµ‹è¯•åœºæ™¯
- **è‡ªåŠ¨åŒ–**: é€æ­¥å®ç°æµ‹è¯•çš„å®Œå…¨è‡ªåŠ¨åŒ–
- **æ–‡åŒ–å»ºè®¾**: åœ¨å›¢é˜Ÿä¸­æ¨å¹¿å¼¹æ€§å·¥ç¨‹æ–‡åŒ–

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-10-10
**ç»´æŠ¤è€…**: EMQX-Go Team
**è®¸å¯è¯**: Apache 2.0
